# -*- coding: utf-8 -*-
import os
import io
import csv
import pickle
import zipfile
from typing import List, Dict, Set
import numpy as np
import pandas as pd
import streamlit as st

# íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ì˜
TYPE_MAPPING = {
    1: "ì„¤ì¹˜í˜•",
    2: "ì‹¤í–‰í˜•", 
    3: "ì°¸ì—¬í˜•",
    4: "í´ë¦­í˜•",
    5: "í˜ë¶",
    6: "íŠ¸ìœ„í„°", 
    7: "ì¸ìŠ¤íƒ€",
    8: "ë…¸ì¶œí˜•",
    9: "í€˜ìŠ¤íŠ¸",
    10: "ìœ íŠœë¸Œ",
    11: "ë„¤ì´ë²„",
    12: "CPS(ë¬¼ê±´êµ¬ë§¤)"
}

CATEGORY_MAPPING = {
    0: "ì¹´í…Œê³ ë¦¬ ì„ íƒì•ˆí•¨",
    1: "ì•±(ê°„í¸ì ë¦½)",
    2: "ê²½í—˜í•˜ê¸°(ê²Œì„ì ë¦½)/ì•±(ê°„í¸ì ë¦½) - cpi,cpe",
    3: "êµ¬ë…(ê°„í¸ì ë¦½)",
    4: "ê°„í¸ë¯¸ì…˜-í€˜ì¦ˆ(ê°„í¸ì ë¦½)",
    5: "ê²½í—˜í•˜ê¸°(ê²Œì„ì ë¦½) - cpa",
    6: "ë©€í‹°ë³´ìƒ(ê²Œì„ì ë¦½)",
    7: "ê¸ˆìœµ(ì°¸ì—¬ì ë¦½)",
    8: "ë¬´ë£Œì°¸ì—¬(ì°¸ì—¬ì ë¦½)",
    10: "ìœ ë£Œì°¸ì—¬(ì°¸ì—¬ì ë¦½)",
    11: "ì‡¼í•‘-ìƒí’ˆë³„ì¹´í…Œê³ ë¦¬(ì‡¼í•‘ì ë¦½)",
    12: "ì œíœ´ëª°(ì‡¼í•‘ì ë¦½)",
    13: "ê°„í¸ë¯¸ì…˜(ê°„í¸ì ë¦½)"
}

def get_type_name(type_num: int) -> str:
    """íƒ€ì… ë²ˆí˜¸ë¥¼ ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    return TYPE_MAPPING.get(type_num, f"íƒ€ì…{type_num}")

def get_category_name(category_num: int) -> str:
    """ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ë¥¼ ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    return CATEGORY_MAPPING.get(category_num, f"ì¹´í…Œê³ ë¦¬{category_num}")

# -----------------------------
# Helpers
# -----------------------------
def infer_feature_cols(df: pd.DataFrame) -> List[str]:
    """Use only core content features: m_*, e_*, p_*, b_*, c_* (exclude *_st, e_session)."""
    cols = []
    for c in df.columns:
        if c.startswith(("m_", "e_", "p_", "b_", "c_")) and c not in ("e_session",):
            if c.endswith("_st"):
                continue
            if pd.api.types.is_numeric_dtype(df[c]):
                cols.append(c)
    if not cols:
        raise ValueError("No feature columns found (m_/e_/p_/b_/c_).")
    return cols

def l2_normalize(mat: np.ndarray, eps: float = 1e-9) -> np.ndarray:
    norms = np.linalg.norm(mat, axis=1, keepdims=True)
    norms = np.maximum(norms, eps)
    return mat / norms

def extract_zip_if_needed():
    """ì••ì¶• íŒŒì¼ì´ ìˆìœ¼ë©´ í•´ì œí•©ë‹ˆë‹¤."""
    zip_file = "correct_interactions.zip"
    target_file = "input/save/correct_interactions.csv"
    
    # ëŒ€ìƒ íŒŒì¼ì´ ì´ë¯¸ ìˆìœ¼ë©´ í•´ì œí•˜ì§€ ì•ŠìŒ
    if os.path.exists(target_file):
        return
    
    # ì••ì¶• íŒŒì¼ì´ ìˆìœ¼ë©´ í•´ì œ
    if os.path.exists(zip_file):
        os.makedirs("input/save", exist_ok=True)
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            zip_ref.extractall("input/save/")
        print(f"âœ… ì••ì¶• íŒŒì¼ í•´ì œ ì™„ë£Œ: {target_file}")
    else:
        print(f"âŒ ì••ì¶• íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {zip_file}")

@st.cache_data(show_spinner=False)
def load_ads(ads_csv: str):
    df = pd.read_csv(ads_csv)
    feat_cols = infer_feature_cols(df)
    meta_cols = ["ads_idx", "ads_code", "ads_type", "ads_category", "ads_name"]
    for c in meta_cols:
        if c not in df.columns:
            raise ValueError(f"Column '{c}' missing in ads CSV.")
    A = df[feat_cols].astype(np.float32).to_numpy()
    A = l2_normalize(A)
    meta = df[meta_cols].copy()
    meta["ads_idx"] = meta["ads_idx"].astype(np.int64)
    meta["ads_code"] = meta["ads_code"].astype(str)
    meta["ads_type"] = meta["ads_type"].astype(np.int32)
    meta["ads_category"] = meta["ads_category"].astype(np.int32)
    meta["ads_name"] = meta["ads_name"].astype(str)
    return A, feat_cols, meta

@st.cache_data(show_spinner=False)
def load_interactions_from_user_profile(user_csv: str):
    """ì‚¬ìš©ì í”„ë¡œí•„ì—ì„œ ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ (ì´ˆê³ ì† ìµœì í™” ë²„ì „)"""
    try:
        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        cache_file = "user_interactions_cache.pkl"
        
        # ìºì‹œ íŒŒì¼ì´ ìˆê³  ì›ë³¸ íŒŒì¼ë³´ë‹¤ ìµœì‹ ì´ë©´ ìºì‹œ ì‚¬ìš©
        if os.path.exists(cache_file) and os.path.exists(user_csv):
            cache_time = os.path.getmtime(cache_file)
            source_time = os.path.getmtime(user_csv)
            if cache_time > source_time:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        
        # ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ê²½ìš° ìƒˆë¡œ ìƒì„± (ì¡°ìš©íˆ ì²˜ë¦¬)
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ
        df = pd.read_csv(user_csv, dtype={"user_device_id": str})
        
        # ìƒí˜¸ì‘ìš© ê´€ë ¨ ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒ
        interaction_cols = [col for col in df.columns if col.startswith(('ads_category_', 'ads_type_'))]
        if not interaction_cols:
            return {}
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
        cols_to_use = ["user_device_id"] + interaction_cols
        df_subset = df[cols_to_use].copy()
        
        user_interactions = {}
        
        # ë²¡í„°í™”ëœ ì—°ì‚°ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
        for _, row in df_subset.iterrows():
            uid = str(row["user_device_id"])
            interacted_categories = []
            interacted_types = []
            
            # ads_category_* ì»¬ëŸ¼ë“¤ì—ì„œ ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            for col in interaction_cols:
                if pd.notna(row[col]) and row[col] > 0:
                    if col.startswith('ads_category_'):
                        category = int(col.replace('ads_category_', ''))
                        interacted_categories.append(category)
                    elif col.startswith('ads_type_'):
                        ad_type = int(col.replace('ads_type_', ''))
                        interacted_types.append(ad_type)
            
            if interacted_categories or interacted_types:
                user_interactions[uid] = {
                    "categories": list(set(interacted_categories)),
                    "types": list(set(interacted_types))
                }
        
        # ê²°ê³¼ë¥¼ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
        with open(cache_file, 'wb') as f:
            pickle.dump(user_interactions, f)
        
        return user_interactions
        
    except Exception as e:
        st.warning(f"ìƒí˜¸ì‘ìš© ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}


@st.cache_data(show_spinner=False)
def load_actual_interactions():
    """ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ (ìƒ˜í”Œ ë°ì´í„°)"""
    try:
        cache_file = "actual_interactions_cache.pkl"
        source_file = "correct_interactions_sample.zip"
        
        if os.path.exists(cache_file) and os.path.exists(source_file):
            cache_time = os.path.getmtime(cache_file)
            source_time = os.path.getmtime(source_file)
            if cache_time > source_time:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        
        # ìƒ˜í”Œ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ (ZIP íŒŒì¼ì—ì„œ)
        with zipfile.ZipFile(source_file, 'r') as zip_ref:
            # ZIP íŒŒì¼ ë‚´ë¶€ì˜ CSV íŒŒì¼ëª… í™•ì¸
            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
            if not csv_files:
                st.warning("ZIP íŒŒì¼ì—ì„œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
            
            # ì²« ë²ˆì§¸ CSV íŒŒì¼ ì‚¬ìš©
            csv_file = csv_files[0]
            with zip_ref.open(csv_file) as f:
                interactions_df = pd.read_csv(f)
        
        # user_device_id ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ user_ip ì‚¬ìš©
        if 'user_device_id' in interactions_df.columns:
            interactions_df['user_device_id'] = interactions_df['user_device_id'].astype(str)
        else:
            interactions_df['user_device_id'] = interactions_df['user_ip'].astype(str)
        
        # user_device_idê°€ nullì´ê±°ë‚˜ ë¹ˆ ê°’ì¸ ê²½ìš° ì œê±°
        interactions_df = interactions_df[interactions_df['user_device_id'].notna() & (interactions_df['user_device_id'] != '')]
        
        # ìƒí˜¸ì‘ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©ìë³„ë¡œ ê·¸ë£¹í™”
        user_actual_interactions = {}
        
        for user_id, group in interactions_df.groupby('user_device_id'):
            user_ads = []
            for _, row in group.iterrows():
                # ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œ interaction_typeì„ ì§ì ‘ ì‚¬ìš©
                interaction_type = row.get('interaction_type', 'í´ë¦­')
                
                user_ads.append({
                    'ads_idx': row['ads_idx'],
                    'ads_type': row.get('ads_type', 0),
                    'ads_category': row.get('ads_category', 0),
                    'ads_name': row.get('ads_name', ''),
                    'interaction_type': interaction_type,
                    'reward_point': row.get('reward_point', 0),
                    'rwd_price': row.get('rwd_price', 0),
                    'click_time': row.get('click_time', ''),
                    'click_date': row.get('click_date', ''),
                    'click_key': row.get('click_key', ''),
                    'click_key_info': row.get('click_key_info', ''),
                    'click_key_rwd': row.get('click_key_rwd', '')
                })
        
            if user_ads:
                user_actual_interactions[user_id] = user_ads
        
        with open(cache_file, 'wb') as f:
            pickle.dump(user_actual_interactions, f)
        
        return user_actual_interactions
        
    except Exception as e:
        st.warning(f"ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

@st.cache_data(show_spinner=False)
def load_detailed_user_interactions(user_csv: str):
    """ì‚¬ìš©ì í”„ë¡œí•„ì—ì„œ ìƒì„¸ ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ"""
    try:
        cache_file = "detailed_user_interactions_cache.pkl"
        
        if os.path.exists(cache_file) and os.path.exists(user_csv):
            cache_time = os.path.getmtime(cache_file)
            source_time = os.path.getmtime(user_csv)
            if cache_time > source_time:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ
        df = pd.read_csv(user_csv, dtype={"user_device_id": str})
        
        # ìƒí˜¸ì‘ìš© ê´€ë ¨ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        interaction_cols = [col for col in df.columns if col.startswith(('ads_category_', 'ads_type_'))]
        
        detailed_interactions = {}
        
        for _, row in df.iterrows():
            uid = str(row["user_device_id"])
            user_interactions = []
            
            # ê° ìƒí˜¸ì‘ìš© ì»¬ëŸ¼ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            for col in interaction_cols:
                if pd.notna(row[col]) and row[col] > 0:
                    if col.startswith('ads_category_'):
                        category = int(col.replace('ads_category_', ''))
                        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ 1ê°œë§Œ ì¶”ê°€ (ì‹¤ì œ ìƒí˜¸ì‘ìš© ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡)
                        # ìƒí˜¸ì‘ìš©ìœ í˜•ì€ reward_point ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
                        interaction_type = 'ì „í™˜' if row.get('total_reward_points', 0) > 0 else 'í´ë¦­'
                        user_interactions.append({
                            'category': category,
                            'type': None,
                            'interaction_type': interaction_type,
                            'count': 1
                        })
                    elif col.startswith('ads_type_'):
                        ad_type = int(col.replace('ads_type_', ''))
                        # íƒ€ì…ë³„ë¡œ 1ê°œë§Œ ì¶”ê°€ (ì‹¤ì œ ìƒí˜¸ì‘ìš© ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡)
                        # ìƒí˜¸ì‘ìš©ìœ í˜•ì€ reward_point ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
                        interaction_type = 'ì „í™˜' if row.get('total_reward_points', 0) > 0 else 'í´ë¦­'
                        user_interactions.append({
                            'category': None,
                            'type': ad_type,
                            'interaction_type': interaction_type,
                            'count': 1
                        })
            
            if user_interactions:
                detailed_interactions[uid] = user_interactions
        
        with open(cache_file, 'wb') as f:
            pickle.dump(detailed_interactions, f)
        
        return detailed_interactions
        
    except Exception as e:
        st.warning(f"ìƒì„¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}

@st.cache_data(show_spinner=False)
def load_users(user_csv: str, feat_cols_hint: List[str]):
    df = pd.read_csv(user_csv, dtype={"user_device_id": str})
    if "user_device_id" not in df.columns:
        raise ValueError("ì‚¬ìš©ì CSVì— 'user_device_id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì‚¬ìš©ì ë°ì´í„°ì—ì„œ pref_ ì ‘ë‘ì‚¬ê°€ ë¶™ì€ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•„ì„œ ë§¤í•‘
    user_feat_cols = []
    for feat in feat_cols_hint:
        pref_feat = f"pref_{feat}"
        if pref_feat in df.columns:
            user_feat_cols.append(pref_feat)
    
    if not user_feat_cols:
        raise ValueError(f"ì‚¬ìš©ì ë°ì´í„°ì— pref_ ì ‘ë‘ì‚¬ê°€ ë¶™ì€ í”¼ì²˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ê´‘ê³  í”¼ì²˜: {feat_cols_hint[:5]}...")
    
    # ì‚¬ìš©ì ë°ì´í„°ì—ì„œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    use = df[["user_device_id"] + user_feat_cols].copy()
    use[user_feat_cols] = use[user_feat_cols].astype(np.float32).fillna(0.0)
    
    # NumPy ë°°ì—´ë¡œ ë³€í™˜
    U = use[user_feat_cols].to_numpy()
    
    # ì°¨ì›ì´ ë§ì§€ ì•Šìœ¼ë©´ ê´‘ê³  í”¼ì²˜ ìˆ˜ì— ë§ì¶°ì„œ ì¡°ì •
    if U.shape[1] > len(feat_cols_hint):
        # ë„ˆë¬´ ë§ìœ¼ë©´ ìë¥´ê¸°
        U = U[:, :len(feat_cols_hint)]
    elif U.shape[1] < len(feat_cols_hint):
        # ë¶€ì¡±í•˜ë©´ 0ìœ¼ë¡œ íŒ¨ë”©
        padding = np.zeros((U.shape[0], len(feat_cols_hint) - U.shape[1]), dtype=np.float32)
        U = np.concatenate([U, padding], axis=1)
    
    U = l2_normalize(U)
    ids = use["user_device_id"].astype(str).to_numpy()
    # ì¸ë±ìŠ¤ ë§µ(ë¹ ë¥¸ ì¡°íšŒ)
    id_to_row = {uid: i for i, uid in enumerate(ids)}
    
    # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ (total_interactions, unique_ads ë“±)
    interaction_info = {}
    if "total_interactions" in df.columns and "unique_ads" in df.columns:
        for _, row in df.iterrows():
            uid = str(row["user_device_id"])
            interaction_info[uid] = {
                "total_interactions": int(row.get("total_interactions", 0)),
                "unique_ads": int(row.get("unique_ads", 0)),
                "total_reward_points": float(row.get("total_reward_points", 0)),
                "avg_dwell_time": float(row.get("avg_dwell_time", 0))
            }
    
    return U, ids, id_to_row, user_feat_cols, interaction_info

# parse_exclude_codes í•¨ìˆ˜ ì œê±° (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

def recommend_for_user(
    uid: str,
    U: np.ndarray,
    user_ids: np.ndarray,
    id_to_row: Dict[str, int],
    A: np.ndarray,
    ads_meta: pd.DataFrame,
    k: int = 20,
    exclude_codes: Set[str] = None
) -> pd.DataFrame:
    if uid not in id_to_row:
        raise KeyError(f"ì‚¬ìš©ì '{uid}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    u = U[id_to_row[uid] : id_to_row[uid] + 1]     # shape (1, d)
    
    # ì°¨ì› í™•ì¸ ë° ë””ë²„ê¹…
    st.write(f"ğŸ” ë””ë²„ê¹…: ì‚¬ìš©ì ë²¡í„° ì°¨ì›: {u.shape}, ê´‘ê³  ë²¡í„° ì°¨ì›: {A.shape}")
    st.write(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ìˆ˜: {u.shape[1]}ê°œ")
    
    # ì°¨ì›ì´ ë§ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€
    if u.shape[1] != A.shape[1]:
        st.error(f"âŒ ì°¨ì› ë¶ˆì¼ì¹˜: ì‚¬ìš©ì {u.shape[1]}ì°¨ì› vs ê´‘ê³  {A.shape[1]}ì°¨ì›")
        st.stop()
    
    # ì½”ì‚¬ì¸ ì ìˆ˜ (A, Uê°€ l2-normalized)
    scores = (u @ A.T).reshape(-1).astype(np.float32)  # (N_ads,)
    
    # ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ê°€ì ¸ì˜¤ê¸°
    user_interacted_types = set()
    user_interacted_categories = set()
    
    # actual_interactionsì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    if uid in actual_interactions and actual_interactions[uid]:
        for interaction in actual_interactions[uid]:
            user_interacted_types.add(interaction.get('ads_type'))
            user_interacted_categories.add(interaction.get('ads_category'))
    
    # íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë³´ë„ˆìŠ¤ ì ìš© (ë™ì  ê³„ì‚°)
    # ì‚¬ìš©ìë³„ ìƒí˜¸ì‘ìš© ë¹ˆë„ì— ë”°ë¥¸ ë™ì  ë³´ë„ˆìŠ¤ ê³„ì‚°
    base_bonus = 0.05  # ê¸°ë³¸ ë³´ë„ˆìŠ¤ ê°’
    type_category_bonus = base_bonus  # í–¥í›„ ë™ì  ê³„ì‚°ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
    
    for i, (_, ad_row) in enumerate(ads_meta.iterrows()):
        ad_type = ad_row['ads_type']
        ad_category = ad_row['ads_category']
        
        # íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ê°€ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        if ad_type in user_interacted_types and ad_category in user_interacted_categories:
            scores[i] += type_category_bonus
        # íƒ€ì…ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        elif ad_type in user_interacted_types:
            scores[i] += type_category_bonus * 0.5
        # ì¹´í…Œê³ ë¦¬ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        elif ad_category in user_interacted_categories:
            scores[i] += type_category_bonus * 0.3
    
    if exclude_codes:
        mask_excl = ads_meta["ads_code"].isin(exclude_codes).to_numpy()
        scores[mask_excl] = -np.inf
    
    take = min(k, scores.shape[0])
    idx = np.argpartition(scores, -take)[-take:]
    idx = idx[np.argsort(-scores[idx])]
    sel = ads_meta.iloc[idx].copy()
    sel.insert(0, "rank", np.arange(1, len(idx) + 1, dtype=np.int32))
    sel["final_score"] = scores[idx].astype(np.float32)
    # ì¶œë ¥ ì—´ ì •ëˆ (ads_name ì¶”ê°€)
    result = sel[["rank","ads_idx","ads_code","ads_name","ads_type","ads_category","final_score"]].copy()
    # íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    result["ads_type"] = result["ads_type"].apply(get_type_name)
    result["ads_category"] = result["ads_category"].apply(get_category_name)
    # ì»¬ëŸ¼ëª…ì„ í•œêµ­ì–´ë¡œ ë³€ê²½
    result.columns = ["ìˆœìœ„", "ê´‘ê³ ì¸ë±ìŠ¤", "ê´‘ê³ ì½”ë“œ", "ê´‘ê³ ëª…", "ê´‘ê³ íƒ€ì…", "ê´‘ê³ ì¹´í…Œê³ ë¦¬", "ìµœì¢…ì ìˆ˜"]
    return result

# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="ì¶”ì²œ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ¯ ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ")

with st.sidebar:
    st.header("ì„¤ì •")
    k = st.slider("ì¶”ì²œ ê°œìˆ˜ (Top-K)", min_value=1, max_value=50, value=20, step=1)
    
    st.markdown("---")
    st.caption("ğŸ’¡ ëŒ€ìš©ëŸ‰ CSVëŠ” ìµœì´ˆ ë¡œë”©ì— ì‹œê°„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ë°ì´í„° ë¡œë“œ
try:
    with st.spinner("ê´‘ê³  ë°ì´í„° ë¡œë”© ì¤‘..."):
        A, feat_cols_ads, ads_meta = load_ads("ads_profile_expanded_sample.zip")
    with st.spinner("ì‚¬ìš©ì ë°ì´í„° ë¡œë”© ì¤‘..."):
        U, user_ids, id_to_row, feat_cols_user, interaction_info = load_users("user_profile_sample.zip", feat_cols_ads)
    with st.spinner("ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë”© ì¤‘..."):
        user_interactions = load_interactions_from_user_profile("user_profile_sample.zip")
        actual_interactions = load_actual_interactions()
        detailed_interactions = load_detailed_user_interactions("user_profile_sample.zip")
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
    st.stop()

# ì‚¬ìš©ì ì„ íƒ
st.subheader("1ï¸âƒ£ ì‚¬ìš©ì ì„ íƒ")
col1, col2 = st.columns([4,1])

with col1:
    st.markdown("**ì‚¬ìš©ì ID ì„ íƒ**")
    if len(user_ids) > 0:
        # ëœë¤ ì„ íƒëœ ì‚¬ìš©ìê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        if "random_uid" in st.session_state:
            random_uid = st.session_state["random_uid"]
            try:
                selected_index = list(user_ids).index(random_uid) + 1  # +1 because of empty option
            except ValueError:
                selected_index = 0
        else:
            selected_index = 0
            
        uid_input = st.selectbox(
            "ì‚¬ìš©ì ì„ íƒ", 
            options=[""] + list(user_ids),
            index=selected_index,
            help="ë“œë¡­ë‹¤ìš´ì—ì„œ ì‚¬ìš©ìë¥¼ ì„ íƒí•˜ì„¸ìš”",
            label_visibility="collapsed"
        )
    else:
        st.warning("ì‚¬ìš©ì ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        uid_input = ""

with col2:
    st.markdown("**ëœë¤ ì„ íƒ**")
    if st.button("ğŸ²", use_container_width=True, help="ë¬´ì‘ìœ„ ì‚¬ìš©ì ì„ íƒ"):
        # ë¬´ì‘ìœ„ í•œ ëª…
        if len(user_ids) > 0:
            random_uid = np.random.choice(user_ids)
            st.session_state["random_uid"] = random_uid
            st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ selectbox ì—…ë°ì´íŠ¸
        else:
            st.warning("ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì¶”ì²œ ì‹¤í–‰
st.subheader("2ï¸âƒ£ ì¶”ì²œ ì‹¤í–‰")
run = st.button("ğŸš€ ì¶”ì²œ ì‹œì‘", type="primary", use_container_width=True)

if run:
    if not uid_input:
        st.warning("ì‚¬ìš©ì IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()
    try:
        with st.spinner("ì½˜í…ì¸  ê¸°ë°˜ Top-K ì¶”ì²œ ê³„ì‚° ì¤‘..."):
            rec = recommend_for_user(
                uid=uid_input,
                U=U,
                user_ids=user_ids,
                id_to_row=id_to_row,
                A=A,
                ads_meta=ads_meta,
                k=k,
                exclude_codes=None
            )
        st.success(f"âœ… ì‚¬ìš©ì {uid_input}ì— ëŒ€í•œ Top-{k} ì¶”ì²œ ê²°ê³¼")
        
        # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ í‘œì‹œ
        if uid_input in interaction_info:
            user_info = interaction_info[uid_input]
            st.markdown("**ğŸ‘¤ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´**")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ì´ ìƒí˜¸ì‘ìš© ìˆ˜ ê³„ì‚°
                if uid_input in actual_interactions and actual_interactions[uid_input]:
                    total_interactions_count = len(actual_interactions[uid_input])
                    st.metric("ì´ ìƒí˜¸ì‘ìš©", total_interactions_count)
                else:
                    st.metric("ì´ ìƒí˜¸ì‘ìš©", user_info["total_interactions"])
            with col2:
                # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ê³ ìœ  ê´‘ê³  ìˆ˜ ê³„ì‚°
                if uid_input in actual_interactions and actual_interactions[uid_input]:
                    unique_ads_count = len(set(interaction['ads_idx'] for interaction in actual_interactions[uid_input]))
                    st.metric("ê³ ìœ  ê´‘ê³  ìˆ˜", unique_ads_count)
                else:
                    st.metric("ê³ ìœ  ê´‘ê³  ìˆ˜", user_info["unique_ads"])
            with col3:
                # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ í´ë¦­+ì „í™˜ì¸ ìƒí˜¸ì‘ìš©ë“¤ì˜ ë¦¬ì›Œë“œ í•© ê³„ì‚°
                if uid_input in actual_interactions and actual_interactions[uid_input]:
                    total_rwd_price = sum(
                        interaction.get('rwd_price', 0) 
                        for interaction in actual_interactions[uid_input] 
                        if interaction.get('interaction_type') == 'í´ë¦­+ì „í™˜'  # í´ë¦­+ì „í™˜ì¸ ìƒí˜¸ì‘ìš©ë§Œ
                    )
                    st.metric("ì´ ë¦¬ì›Œë“œ ê¸ˆì•¡", f"{total_rwd_price:.0f}ì› ({total_rwd_price:.0f}í¬ì¸íŠ¸)")
                else:
                    st.metric("ì´ ë¦¬ì›Œë“œ ê¸ˆì•¡", f"{user_info['total_reward_points']:.0f}ì› ({user_info['total_reward_points']:.0f}í¬ì¸íŠ¸)")
        
        # ì‚¬ìš©ìê°€ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡ í‘œì‹œ
        st.markdown("**ğŸ“‹ ì‚¬ìš©ìê°€ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡**")
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ì‚¬ìš©
        if uid_input in actual_interactions and actual_interactions[uid_input]:
            # ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë“¤ í‘œì‹œ (ì¤‘ë³µ ì§‘ê³„)
            actual_ads = {}
            for interaction in actual_interactions[uid_input]:
                ads_idx = interaction['ads_idx']
                # ads_idxë¡œ ê´‘ê³  ì •ë³´ ì°¾ê¸°
                ad_info = ads_meta[ads_meta['ads_idx'] == ads_idx]
                if len(ad_info) > 0:
                    ad_row = ad_info.iloc[0]
                    # ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œëŠ” interaction_typeì´ ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ë¨
                    clean_interaction_type = str(interaction['interaction_type'])
                    
                    # ê´‘ê³ ë³„ë¡œ ìƒí˜¸ì‘ìš© ì§‘ê³„
                    ad_key = f"{ad_row['ads_code']}_{clean_interaction_type}"
                    if ad_key not in actual_ads:
                        actual_ads[ad_key] = {
                            "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                            "ê´‘ê³ ëª…": ad_row["ads_name"],
                            "ê´‘ê³ íƒ€ì…": get_type_name(ad_row["ads_type"]),
                            "ê´‘ê³ ì¹´í…Œê³ ë¦¬": get_category_name(ad_row["ads_category"]),
                            "ìƒí˜¸ì‘ìš©ìœ í˜•": clean_interaction_type,
                            "ìƒí˜¸ì‘ìš©íšŸìˆ˜": 0
                        }
                    actual_ads[ad_key]["ìƒí˜¸ì‘ìš©íšŸìˆ˜"] += 1
            
            # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            actual_ads_list = list(actual_ads.values())
            
            if actual_ads_list:
                actual_df = pd.DataFrame(actual_ads_list)
                st.dataframe(actual_df, use_container_width=True, hide_index=True)
                st.info(f"ğŸ’¡ ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡ì…ë‹ˆë‹¤. (ì´ {len(actual_ads_list)}ê°œ)")
            else:
                st.info("ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒì„¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ì‚¬ìš©
        elif uid_input in detailed_interactions and detailed_interactions[uid_input]:
            # ìƒì„¸ ìƒí˜¸ì‘ìš© ì •ë³´ë¡œ ì‹¤ì œ ê´‘ê³ ë“¤ ìƒì„±
            detailed_ads = []
            max_interactions = user_info.get("total_interactions", 0)
            
            for interaction in detailed_interactions[uid_input]:
                # ì´ ìƒí˜¸ì‘ìš© ìˆ˜ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œ
                if len(detailed_ads) >= max_interactions:
                    break
                    
                if interaction['category'] is not None:
                    # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê´‘ê³  ì°¾ê¸°
                    category_ads = ads_meta[ads_meta["ads_category"] == interaction['category']]
                    if len(category_ads) > 0:
                        # ëœë¤í•˜ê²Œ ì„ íƒ (ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜)
                        ad_row = category_ads.sample(1).iloc[0]
                        detailed_ads.append({
                            "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                            "ê´‘ê³ ëª…": ad_row["ads_name"],
                            "ê´‘ê³ íƒ€ì…": get_type_name(ad_row["ads_type"]),
                            "ê´‘ê³ ì¹´í…Œê³ ë¦¬": get_category_name(ad_row["ads_category"]),
                            "ìƒí˜¸ì‘ìš©ìœ í˜•": interaction['interaction_type'],
                            "ìƒí˜¸ì‘ìš©íšŸìˆ˜": interaction['count']
                        })
                
                if interaction['type'] is not None and len(detailed_ads) < max_interactions:
                    # íƒ€ì… ê¸°ë°˜ ê´‘ê³  ì°¾ê¸°
                    type_ads = ads_meta[ads_meta["ads_type"] == interaction['type']]
                    if len(type_ads) > 0:
                        # ëœë¤í•˜ê²Œ ì„ íƒ (ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜)
                        ad_row = type_ads.sample(1).iloc[0]
                        # ì¤‘ë³µ ë°©ì§€
                        if not any(ad["ê´‘ê³ ì½”ë“œ"] == ad_row["ads_code"] for ad in detailed_ads):
                            detailed_ads.append({
                                "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                                "ê´‘ê³ ëª…": ad_row["ads_name"],
                                "ê´‘ê³ íƒ€ì…": get_type_name(ad_row["ads_type"]),
                                "ê´‘ê³ ì¹´í…Œê³ ë¦¬": get_category_name(ad_row["ads_category"]),
                                "ìƒí˜¸ì‘ìš©ìœ í˜•": interaction['interaction_type'],
                                "ìƒí˜¸ì‘ìš©íšŸìˆ˜": interaction['count']
                            })
            
            if detailed_ads:
                detailed_df = pd.DataFrame(detailed_ads)
                st.dataframe(detailed_df, use_container_width=True, hide_index=True)
                st.info(f"ğŸ’¡ ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡ì…ë‹ˆë‹¤. (ì´ {len(detailed_ads)}ê°œ)")
            else:
                st.info("ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ëŒ€í‘œ ê´‘ê³  ì‚¬ìš©
        elif uid_input in user_interactions and user_interactions[uid_input]:
            # ëŒ€í‘œ ê´‘ê³  í‘œì‹œ (ê¸°ì¡´ ë¡œì§)
            interaction_data = user_interactions[uid_input]
            categories = interaction_data.get("categories", [])
            types = interaction_data.get("types", [])
            
            # ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë§Œ í‘œì‹œ (ì´ ìƒí˜¸ì‘ìš© ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡)
            interacted_ads = []
            
            # ì‹¤ì œ ìƒí˜¸ì‘ìš© íŒ¨í„´ì— ë”°ë¼ ê´‘ê³  í‘œì‹œ
            for category in categories:
                if len(interacted_ads) >= user_info.get("total_interactions", 0):
                    break
                
                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê´‘ê³  ì¤‘ì—ì„œ ìƒí˜¸ì‘ìš©í•œ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì°¾ê¸°
                category_ads = ads_meta[ads_meta["ads_category"] == category]
                
                # ìƒí˜¸ì‘ìš©í•œ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ” ê´‘ê³ ê°€ ìˆëŠ”ì§€ í™•ì¸
                matching_ads = category_ads[category_ads["ads_type"].isin(types)]
                
                if len(matching_ads) > 0:
                    # êµì§‘í•©ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê´‘ê³  ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ì™€ íƒ€ì… ëª¨ë‘ ìƒí˜¸ì‘ìš©)
                    ad_row = matching_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "í´ë¦­+ì „í™˜"
                    })
                else:
                    # êµì§‘í•©ì´ ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ë§Œ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ë§Œ ìƒí˜¸ì‘ìš©)
                    ad_row = category_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "í´ë¦­"
                    })
            
            # íƒ€ì… ê¸°ë°˜ ê´‘ê³  ì°¾ê¸° (ì¹´í…Œê³ ë¦¬ì™€ êµì§‘í•©ì´ ì—†ëŠ” ê²½ìš°ë§Œ)
            for ad_type in types:
                if len(interacted_ads) >= user_info.get("total_interactions", 0):
                    break
                
                # ì´ë¯¸ í•´ë‹¹ íƒ€ì…ì´ í¬í•¨ëœ ê´‘ê³ ê°€ ìˆëŠ”ì§€ í™•ì¸
                if any(ad["ê´‘ê³ íƒ€ì…"] == ad_type for ad in interacted_ads):
                    continue
                
                # í•´ë‹¹ íƒ€ì…ì˜ ê´‘ê³  ì¤‘ì—ì„œ ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì°¾ê¸°
                type_ads = ads_meta[ads_meta["ads_type"] == ad_type]
                matching_ads = type_ads[type_ads["ads_category"].isin(categories)]
                
                if len(matching_ads) > 0:
                    # êµì§‘í•©ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê´‘ê³  ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ì™€ íƒ€ì… ëª¨ë‘ ìƒí˜¸ì‘ìš©)
                    ad_row = matching_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "í´ë¦­+ì „í™˜"
                    })
                else:
                    # êµì§‘í•©ì´ ì—†ìœ¼ë©´ íƒ€ì…ë§Œ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì‚¬ìš© (íƒ€ì…ë§Œ ìƒí˜¸ì‘ìš©)
                    ad_row = type_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "ì „í™˜"
                    })
            
            if interacted_ads:
                interacted_df = pd.DataFrame(interacted_ads)
                st.dataframe(interacted_df, use_container_width=True, hide_index=True)
                
                # ìš”ì•½ ì •ë³´
                st.info(f"ğŸ’¡ ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬/íƒ€ì…ì˜ ëŒ€í‘œ ê´‘ê³ ì…ë‹ˆë‹¤. (ì´ {len(interacted_ads)}ê°œ)")
            else:
                st.info("ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì´ ì‚¬ìš©ìëŠ” ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ì‚¬ìš©ì ì„ í˜¸ë„ vs ì¶”ì²œ ê²°ê³¼ ë¹„êµ
        st.markdown("**ğŸ¯ ì‚¬ìš©ì ì„ í˜¸ë„ vs ì¶”ì²œ ê²°ê³¼ ë¹„êµ**")
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        user_vector = U[id_to_row[uid_input]]
        
        # ì¶”ì²œëœ ê´‘ê³ ë“¤ì˜ í”¼ì²˜ ë²¡í„°
        rec_ads_idx = rec["ê´‘ê³ ì¸ë±ìŠ¤"].values
        # ê´‘ê³  ì¸ë±ìŠ¤ë¥¼ ë°°ì—´ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        rec_ads_features = []
        for ads_idx in rec_ads_idx:
            # ads_metaì—ì„œ í•´ë‹¹ ê´‘ê³ ì˜ í–‰ ì¸ë±ìŠ¤ ì°¾ê¸°
            ad_row_idx = ads_meta[ads_meta['ads_idx'] == ads_idx].index
            if len(ad_row_idx) > 0:
                rec_ads_features.append(A[ad_row_idx[0]])
            else:
                # ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ 0 ë²¡í„° ì‚¬ìš©
                rec_ads_features.append(np.zeros(A.shape[1]))
        rec_ads_features = np.array(rec_ads_features)
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ì™€ ê° ì¶”ì²œ ê´‘ê³ ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = (user_vector @ rec_ads_features.T).flatten()
        
        # ë¹„êµ ì°¨íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“ˆ ì¶”ì²œ ê´‘ê³ ë³„ ìœ ì‚¬ë„**")
            # ìœ ì‚¬ë„ë¥¼ ì„¸ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ë¡œ í‘œì‹œ (Xì¶• ë ˆì´ë¸” ì„¸ë¡œ íšŒì „)
            import plotly.express as px
            sim_data = pd.DataFrame({
                "ìˆœìœ„": rec["ìˆœìœ„"],
                "ìœ ì‚¬ë„": similarities
            })
            fig = px.bar(sim_data, x="ìˆœìœ„", y="ìœ ì‚¬ë„", title="ì¶”ì²œ ê´‘ê³ ë³„ ìœ ì‚¬ë„")
            fig.update_layout(
                xaxis_tickangle=-90,  # Xì¶• ë ˆì´ë¸”ì„ 90ë„ íšŒì „
                height=300,
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("**ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„í¬**")
            # ì¹´í…Œê³ ë¦¬ ë¶„í¬ë¥¼ ì„¸ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ë¡œ í‘œì‹œ (Xì¶• ë ˆì´ë¸” ì„¸ë¡œ íšŒì „)
            # ì›ë³¸ ìˆ«ì ì¹´í…Œê³ ë¦¬ ì‚¬ìš© (ë§¤í•‘ ì „ ì›ë³¸ ë°ì´í„° ì‚¬ìš©)
            cat_counts = {}
            for _, row in rec.iterrows():
                ads_idx = row["ê´‘ê³ ì¸ë±ìŠ¤"]
                ad_row = ads_meta[ads_meta['ads_idx'] == ads_idx]
                if not ad_row.empty:
                    original_category = ad_row.iloc[0]['ads_category']
                    cat_counts[original_category] = cat_counts.get(original_category, 0) + 1
            
            # ìˆ«ì ì¹´í…Œê³ ë¦¬ë¡œ ì •ë ¬í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
            cat_data = pd.DataFrame({
                "ì¹´í…Œê³ ë¦¬": sorted(cat_counts.keys()),
                "ê°œìˆ˜": [cat_counts.get(cat, 0) for cat in sorted(cat_counts.keys())]
            })
            fig = px.bar(cat_data, x="ì¹´í…Œê³ ë¦¬", y="ê°œìˆ˜", title="ì¹´í…Œê³ ë¦¬ ë¶„í¬")
            fig.update_layout(
                xaxis_tickangle=-90,  # Xì¶• ë ˆì´ë¸”ì„ 90ë„ íšŒì „
                height=300,
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # ìœ ì‚¬ë„ í†µê³„
        st.markdown("**ğŸ“‹ ìœ ì‚¬ë„ ë¶„ì„**")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("í‰ê·  ìœ ì‚¬ë„", f"{similarities.mean():.4f}")
        with col2:
            st.metric("ìµœê³  ìœ ì‚¬ë„", f"{similarities.max():.4f}")
        with col3:
            st.metric("ìµœì € ìœ ì‚¬ë„", f"{similarities.min():.4f}")
        with col4:
            st.metric("ìœ ì‚¬ë„ í‘œì¤€í¸ì°¨", f"{similarities.std():.4f}")
        
        # ìƒì„¸ ë¶„ì„ í…Œì´ë¸”
        st.markdown("**ğŸ” ì¶”ì²œ ê´‘ê³  ìƒì„¸ ë¶„ì„**")
        
        # ìµœì¢…ì ìˆ˜ ê³„ì‚° ë°©ì‹ ì„¤ëª…
        with st.expander("ğŸ“Š ìµœì¢…ì ìˆ˜ ê³„ì‚° ë°©ì‹"):
            st.markdown(f"""
            **ìµœì¢…ì ìˆ˜ = ì½˜í…ì¸  ìœ ì‚¬ë„ + íƒ€ì…/ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë³´ë„ˆìŠ¤**
            
            **1. ì½˜í…ì¸  ìœ ì‚¬ë„ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)**
            - **ì‚¬ìš©ì ë²¡í„° (U)**: ì‚¬ìš©ìì˜ ì„ í˜¸ë„ í”¼ì²˜ ë²¡í„° (60ì°¨ì›)
            - **ê´‘ê³  ë²¡í„° (A)**: ê´‘ê³ ì˜ ì½˜í…ì¸  í”¼ì²˜ ë²¡í„° (60ì°¨ì›)
            - **ê³„ì‚° ë°©ì‹**: `scores = user_vector @ ads_features.T`
            - **ì •ê·œí™”**: L2 ì •ê·œí™”ëœ ë²¡í„°ë“¤ì˜ ë‚´ì  (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            - **ë²”ìœ„**: -1 ~ 1 (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨)
            
            **2. íƒ€ì…/ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë³´ë„ˆìŠ¤ (ê³ ì •ê°’: 0.05)**
            - **íƒ€ì…+ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì¼ì¹˜**: +0.05 (100% ë³´ë„ˆìŠ¤)
            - **íƒ€ì…ë§Œ ì¼ì¹˜**: +0.025 (50% ë³´ë„ˆìŠ¤)
            - **ì¹´í…Œê³ ë¦¬ë§Œ ì¼ì¹˜**: +0.015 (30% ë³´ë„ˆìŠ¤)
            
            **ì¶”ê°€ ë¶„ì„ ìš”ì†Œë“¤:**
            - **ìœ ì‚¬ë„**: ì½˜í…ì¸  ìœ ì‚¬ë„ (ë³´ë„ˆìŠ¤ ì ìš© ì „)
            - **íƒ€ì…ì„ í˜¸ë„**: ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë°˜ íƒ€ì… ì„ í˜¸ë„
            - **ì¹´í…Œê³ ë¦¬ì„ í˜¸ë„**: ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
            - **ìƒëŒ€ìˆœìœ„(%)**: ì „ì²´ ì¶”ì²œ ì¤‘ì—ì„œì˜ ë°±ë¶„ìœ„ ìˆœìœ„
            """)
        detailed_df = rec.copy()
        detailed_df["ìœ ì‚¬ë„"] = similarities
        
        # ì¶”ê°€ ë¶„ì„ ì •ë³´ ê³„ì‚°
        user_vector = U[id_to_row[uid_input]]
        
        # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ê³„ì‚° (ì‹¤ì œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ê¸°ë°˜ ë™ì  ê³„ì‚°)
        category_preferences = []
        type_preferences = []
        
        # ì‚¬ìš©ìë³„ ì¹´í…Œê³ ë¦¬/íƒ€ì… ì„ í˜¸ë„ ê³„ì‚° (ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„° ê¸°ë°˜)
        user_cat_prefs = {}
        user_type_prefs = {}
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ì—ì„œ ì„ í˜¸ë„ ê³„ì‚°
        if uid_input in actual_interactions:
            user_ads = actual_interactions[uid_input]
            
            # ì¹´í…Œê³ ë¦¬ë³„ ìƒí˜¸ì‘ìš© ë¹ˆë„ ê³„ì‚°
            cat_counts = {}
            type_counts = {}
            total_interactions = len(user_ads)
            
            for ad in user_ads:
                cat = ad.get("ads_category")
                ad_type = ad.get("ads_type")
                
                if cat is not None:
                    cat_counts[cat] = cat_counts.get(cat, 0) + 1
                if ad_type is not None:
                    type_counts[ad_type] = type_counts.get(ad_type, 0) + 1
            
            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (íƒ€ì… 0.4~0.8, ì¹´í…Œê³ ë¦¬ 0.3~0.8 ë²”ìœ„ë¡œ ì •ê·œí™”)
            # ìµœì†Œ ì„ í˜¸ë„: íƒ€ì… 0.4, ì¹´í…Œê³ ë¦¬ 0.3
            # ìµœëŒ€ ì„ í˜¸ë„: íƒ€ì… 0.8, ì¹´í…Œê³ ë¦¬ 0.8
            for cat, count in cat_counts.items():
                # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„: 0.3 + (ìƒí˜¸ì‘ìš© ë¹„ìœ¨ * 0.5)
                interaction_ratio = count / max(total_interactions, 1)
                user_cat_prefs[cat] = 0.3 + (interaction_ratio * 0.5)
            
            for ad_type, count in type_counts.items():
                # íƒ€ì… ì„ í˜¸ë„: 0.4 + (ìƒí˜¸ì‘ìš© ë¹„ìœ¨ * 0.4)
                interaction_ratio = count / max(total_interactions, 1)
                user_type_prefs[ad_type] = 0.4 + (interaction_ratio * 0.4)
        
        # ì›ë³¸ ìˆ«ì ë°ì´í„°ë¡œ ì„ í˜¸ë„ ê³„ì‚° (ë§¤í•‘ ì „ ë°ì´í„° ì‚¬ìš©)
        for _, row in detailed_df.iterrows():
            # ì›ë³¸ ê´‘ê³  ë°ì´í„°ì—ì„œ íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ê°€ì ¸ì˜¤ê¸°
            ads_idx = row["ê´‘ê³ ì¸ë±ìŠ¤"]
            ad_row = ads_meta[ads_meta['ads_idx'] == ads_idx]
            
            if not ad_row.empty:
                # ì›ë³¸ ìˆ«ì íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
                original_type = ad_row.iloc[0]['ads_type']
                original_category = ad_row.iloc[0]['ads_category']
                
                # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ (ì‹¤ì œ ìƒí˜¸ì‘ìš© ë¹ˆë„ ê¸°ë°˜)
                if original_category in user_cat_prefs:
                    cat_pref = user_cat_prefs[original_category]
                else:
                    # ìƒí˜¸ì‘ìš©í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ëŠ” ìµœì†Œ ì„ í˜¸ë„
                    cat_pref = 0.3
                category_preferences.append(cat_pref)
                
                # íƒ€ì… ì„ í˜¸ë„ (ì‹¤ì œ ìƒí˜¸ì‘ìš© ë¹ˆë„ ê¸°ë°˜)
                if original_type in user_type_prefs:
                    type_pref = user_type_prefs[original_type]
                else:
                    # ìƒí˜¸ì‘ìš©í•˜ì§€ ì•Šì€ íƒ€ì…ì€ ìµœì†Œ ì„ í˜¸ë„
                    type_pref = 0.4
                type_preferences.append(type_pref)
            else:
                # ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ìµœì†Œ ì„ í˜¸ë„
                category_preferences.append(0.3)
                type_preferences.append(0.4)
        
        detailed_df["ì¹´í…Œê³ ë¦¬ì„ í˜¸ë„"] = category_preferences
        detailed_df["íƒ€ì…ì„ í˜¸ë„"] = type_preferences
        
        # ìƒëŒ€ì  ìˆœìœ„ (ì „ì²´ ê´‘ê³  ì¤‘ì—ì„œì˜ ë°±ë¶„ìœ„)
        total_ads = len(ads_meta)
        relative_ranks = []
        for rank in detailed_df["ìˆœìœ„"]:
            percentile = (1 - (rank - 1) / len(detailed_df)) * 100
            relative_ranks.append(percentile)
        detailed_df["ìƒëŒ€ìˆœìœ„(%)"] = relative_ranks
        
        # íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜ (í…Œì´ë¸” í‘œì‹œìš©, ì ‘ë‘ì‚¬ ì œê±°)
        detailed_df["ê´‘ê³ íƒ€ì…"] = detailed_df["ê´‘ê³ íƒ€ì…"].apply(lambda x: get_type_name(x).replace("íƒ€ì…", ""))
        detailed_df["ê´‘ê³ ì¹´í…Œê³ ë¦¬"] = detailed_df["ê´‘ê³ ì¹´í…Œê³ ë¦¬"].apply(lambda x: get_category_name(x).replace("ì¹´í…Œê³ ë¦¬", ""))
        
        # ìµœì¢… í…Œì´ë¸” êµ¬ì„±
        detailed_df = detailed_df[["ìˆœìœ„", "ê´‘ê³ ì½”ë“œ", "ê´‘ê³ ëª…", "ê´‘ê³ íƒ€ì…", "ê´‘ê³ ì¹´í…Œê³ ë¦¬", 
                                 "ìµœì¢…ì ìˆ˜", "ìœ ì‚¬ë„", "íƒ€ì…ì„ í˜¸ë„", "ì¹´í…Œê³ ë¦¬ì„ í˜¸ë„", "ìƒëŒ€ìˆœìœ„(%)"]]
        
        st.dataframe(detailed_df, use_container_width=True, hide_index=True)

        # ë‹¤ìš´ë¡œë“œ
        csv_bytes = rec.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_bytes,
            file_name=f"top{k}_{uid_input}_recommendations.csv",
            mime="text/csv",
            use_container_width=True
        )

    except KeyError as e:
        st.error(f"ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        st.error(f"ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì•± ì‹œì‘ ì‹œ ì••ì¶• íŒŒì¼ í•´ì œ
if __name__ == "__main__":
    extract_zip_if_needed()
