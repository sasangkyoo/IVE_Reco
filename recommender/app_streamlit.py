# -*- coding: utf-8 -*-
import os
import io
import csv
import pickle
import zipfile
from typing import List, Dict, Set
import numpy as np
import pandas as pd
import streamlit as st

# -----------------------------
# Helpers
# -----------------------------
def infer_feature_cols(df: pd.DataFrame) -> List[str]:
    """Use only core content features: m_*, e_*, p_*, b_*, c_* (exclude *_st, e_session)."""
    cols = []
    for c in df.columns:
        if c.startswith(("m_", "e_", "p_", "b_", "c_")) and c not in ("e_session",):
            if c.endswith("_st"):
                continue
            if pd.api.types.is_numeric_dtype(df[c]):
                cols.append(c)
    if not cols:
        raise ValueError("No feature columns found (m_/e_/p_/b_/c_).")
    return cols

def l2_normalize(mat: np.ndarray, eps: float = 1e-9) -> np.ndarray:
    norms = np.linalg.norm(mat, axis=1, keepdims=True)
    norms = np.maximum(norms, eps)
    return mat / norms

# ì••ì¶• í•´ì œ ê¸°ëŠ¥ ì œê±° - ì••ì¶• íŒŒì¼ì„ ì§ì ‘ ì‚¬ìš©

@st.cache_data(show_spinner=False)
def load_ads(ads_csv: str):
    # ì••ì¶• íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
    # UploadedFile ê°ì²´ì¸ ê²½ìš° íŒŒì¼ëª… í™•ì¸
    if hasattr(ads_csv, 'name'):
        file_name = ads_csv.name
    else:
        file_name = str(ads_csv)
        
    if file_name.endswith('.zip'):
        with zipfile.ZipFile(ads_csv, 'r') as zip_ref:
            # ZIP íŒŒì¼ ë‚´ì˜ CSV íŒŒì¼ëª… ì°¾ê¸°
            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
            if csv_files:
                with zip_ref.open(csv_files[0]) as f:
                    df = pd.read_csv(f)
            else:
                raise FileNotFoundError(f"No CSV file found in {ads_csv}")
    else:
        df = pd.read_csv(ads_csv)
    feat_cols = infer_feature_cols(df)
    meta_cols = ["ads_idx", "ads_code", "ads_type", "ads_category", "ads_name"]
    for c in meta_cols:
        if c not in df.columns:
            raise ValueError(f"Column '{c}' missing in ads CSV.")
    A = df[feat_cols].astype(np.float32).to_numpy()
    A = l2_normalize(A)
    meta = df[meta_cols].copy()
    meta["ads_idx"] = meta["ads_idx"].astype(np.int64)
    meta["ads_code"] = meta["ads_code"].astype(str)
    meta["ads_type"] = meta["ads_type"].astype(np.int32)
    meta["ads_category"] = meta["ads_category"].astype(np.int32)
    meta["ads_name"] = meta["ads_name"].astype(str)
    return A, feat_cols, meta

@st.cache_data(show_spinner=False)
def load_interactions_from_user_profile(user_csv: str):
    """ì‚¬ìš©ì í”„ë¡œí•„ì—ì„œ ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ (ì´ˆê³ ì† ìµœì í™” ë²„ì „)"""
    try:
        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        cache_file = "user_interactions_cache.pkl"
        
        # ìºì‹œ íŒŒì¼ì´ ìˆê³  ì›ë³¸ íŒŒì¼ë³´ë‹¤ ìµœì‹ ì´ë©´ ìºì‹œ ì‚¬ìš©
        if os.path.exists(cache_file) and os.path.exists(user_csv):
            cache_time = os.path.getmtime(cache_file)
            source_time = os.path.getmtime(user_csv)
            if cache_time > source_time:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        
        # ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ê²½ìš° ìƒˆë¡œ ìƒì„± (ì¡°ìš©íˆ ì²˜ë¦¬)
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ
        df = pd.read_csv(user_csv, dtype={"user_device_id": str})
        
        # ìƒí˜¸ì‘ìš© ê´€ë ¨ ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒ
        interaction_cols = [col for col in df.columns if col.startswith(('ads_category_', 'ads_type_'))]
        if not interaction_cols:
            return {}
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
        cols_to_use = ["user_device_id"] + interaction_cols
        df_subset = df[cols_to_use].copy()
        
        user_interactions = {}
        
        # ë²¡í„°í™”ëœ ì—°ì‚°ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
        for _, row in df_subset.iterrows():
            uid = str(row["user_device_id"])
            interacted_categories = []
            interacted_types = []
            
            # ads_category_* ì»¬ëŸ¼ë“¤ì—ì„œ ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            for col in interaction_cols:
                if pd.notna(row[col]) and row[col] > 0:
                    if col.startswith('ads_category_'):
                        category = int(col.replace('ads_category_', ''))
                        interacted_categories.append(category)
                    elif col.startswith('ads_type_'):
                        ad_type = int(col.replace('ads_type_', ''))
                        interacted_types.append(ad_type)
            
            if interacted_categories or interacted_types:
                user_interactions[uid] = {
                    "categories": list(set(interacted_categories)),
                    "types": list(set(interacted_types))
                }
        
        # ê²°ê³¼ë¥¼ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
        with open(cache_file, 'wb') as f:
            pickle.dump(user_interactions, f)
        
        return user_interactions
        
    except Exception as e:
        st.warning(f"ìƒí˜¸ì‘ìš© ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}


@st.cache_data(show_spinner=False)
def load_actual_interactions(source_file="correct_interactions.zip"):
    """ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ (ì›ë³¸ ë°ì´í„°)"""
    try:
        cache_file = "actual_interactions_cache.pkl"
        
        if os.path.exists(cache_file) and os.path.exists(source_file):
            cache_time = os.path.getmtime(cache_file)
            source_time = os.path.getmtime(source_file)
            if cache_time > source_time:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        
        # ì›ë³¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ (ì••ì¶• íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°, ìƒ˜í”Œë§ìœ¼ë¡œ ìµœì í™”)
        # UploadedFile ê°ì²´ì¸ ê²½ìš° íŒŒì¼ëª… í™•ì¸
        if hasattr(source_file, 'name'):
            file_name = source_file.name
        else:
            file_name = str(source_file)
            
        if file_name.endswith('.zip'):
            with zipfile.ZipFile(source_file, 'r') as zip_ref:
                csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                if csv_files:
                    with zip_ref.open(csv_files[0]) as f:
                        # ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ìœ„í•´ ìƒ˜í”Œë§ (10%ë§Œ ì‚¬ìš©)
                        interactions_df = pd.read_csv(f, dtype={
                            'user_device_id': 'string',
                            'ads_idx': 'int32',
                            'interaction_type': 'string',
                            'rwd_price': 'float32',
                            'reward_point': 'float32'
                        }, low_memory=False)
                        # 100,000í–‰ìœ¼ë¡œ ì œí•œí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
                        if len(interactions_df) > 100000:
                            interactions_df = interactions_df.sample(n=100000, random_state=42)
                else:
                    raise FileNotFoundError(f"No CSV file found in {source_file}")
        else:
            interactions_df = pd.read_csv(source_file, dtype={
                'user_device_id': 'string',
                'ads_idx': 'int32',
                'interaction_type': 'string',
                'rwd_price': 'float32',
                'reward_point': 'float32'
            }, low_memory=False)
            # 100,000í–‰ìœ¼ë¡œ ì œí•œí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
            if len(interactions_df) > 100000:
                interactions_df = interactions_df.sample(n=100000, random_state=42)
        
        # user_device_id ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ user_ip ì‚¬ìš©
        if 'user_device_id' in interactions_df.columns:
            interactions_df['user_device_id'] = interactions_df['user_device_id'].astype(str)
        else:
            interactions_df['user_device_id'] = interactions_df['user_ip'].astype(str)
        
        # user_device_idê°€ nullì´ê±°ë‚˜ ë¹ˆ ê°’ì¸ ê²½ìš° ì œê±°
        interactions_df = interactions_df[interactions_df['user_device_id'].notna() & (interactions_df['user_device_id'] != '')]
        
        # ìƒí˜¸ì‘ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©ìë³„ë¡œ ê·¸ë£¹í™”
        user_actual_interactions = {}
        
        for user_id, group in interactions_df.groupby('user_device_id'):
            user_ads = []
            for _, row in group.iterrows():
                # ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œ interaction_typeì„ ì§ì ‘ ì‚¬ìš©
                interaction_type = row.get('interaction_type', 'í´ë¦­')
                
                user_ads.append({
                    'ads_idx': row['ads_idx'],
                    'ads_type': row.get('ads_type', 0),
                    'ads_category': row.get('ads_category', 0),
                    'ads_name': row.get('ads_name', ''),
                    'interaction_type': interaction_type,
                    'reward_point': row.get('reward_point', 0),
                    'rwd_price': row.get('rwd_price', 0),
                    'click_time': row.get('click_time', ''),
                    'click_date': row.get('click_date', ''),
                    'click_key': row.get('click_key', ''),
                    'click_key_info': row.get('click_key_info', ''),
                    'click_key_rwd': row.get('click_key_rwd', '')
                })
        
            if user_ads:
                user_actual_interactions[user_id] = user_ads
        
        with open(cache_file, 'wb') as f:
            pickle.dump(user_actual_interactions, f)
        
        return user_actual_interactions
        
    except Exception as e:
        st.warning(f"ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

@st.cache_data(show_spinner=False)
def load_detailed_user_interactions(user_csv: str):
    """ì‚¬ìš©ì í”„ë¡œí•„ì—ì„œ ìƒì„¸ ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ"""
    try:
        cache_file = "detailed_user_interactions_cache.pkl"
        
        if os.path.exists(cache_file) and os.path.exists(user_csv):
            cache_time = os.path.getmtime(cache_file)
            source_time = os.path.getmtime(user_csv)
            if cache_time > source_time:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ
        df = pd.read_csv(user_csv, dtype={"user_device_id": str})
        
        # ìƒí˜¸ì‘ìš© ê´€ë ¨ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        interaction_cols = [col for col in df.columns if col.startswith(('ads_category_', 'ads_type_'))]
        
        detailed_interactions = {}
        
        for _, row in df.iterrows():
            uid = str(row["user_device_id"])
            user_interactions = []
            
            # ê° ìƒí˜¸ì‘ìš© ì»¬ëŸ¼ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            for col in interaction_cols:
                if pd.notna(row[col]) and row[col] > 0:
                    if col.startswith('ads_category_'):
                        category = int(col.replace('ads_category_', ''))
                        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ 1ê°œë§Œ ì¶”ê°€ (ì‹¤ì œ ìƒí˜¸ì‘ìš© ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡)
                        # ìƒí˜¸ì‘ìš©ìœ í˜•ì€ reward_point ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
                        interaction_type = 'ì „í™˜' if row.get('total_reward_points', 0) > 0 else 'í´ë¦­'
                        user_interactions.append({
                            'category': category,
                            'type': None,
                            'interaction_type': interaction_type,
                            'count': 1
                        })
                    elif col.startswith('ads_type_'):
                        ad_type = int(col.replace('ads_type_', ''))
                        # íƒ€ì…ë³„ë¡œ 1ê°œë§Œ ì¶”ê°€ (ì‹¤ì œ ìƒí˜¸ì‘ìš© ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡)
                        # ìƒí˜¸ì‘ìš©ìœ í˜•ì€ reward_point ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
                        interaction_type = 'ì „í™˜' if row.get('total_reward_points', 0) > 0 else 'í´ë¦­'
                        user_interactions.append({
                            'category': None,
                            'type': ad_type,
                            'interaction_type': interaction_type,
                            'count': 1
                        })
            
            if user_interactions:
                detailed_interactions[uid] = user_interactions
        
        with open(cache_file, 'wb') as f:
            pickle.dump(detailed_interactions, f)
        
        return detailed_interactions
        
    except Exception as e:
        st.warning(f"ìƒì„¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}

@st.cache_data(show_spinner=False)
def load_users(user_csv: str, feat_cols_hint: List[str]):
    # ì••ì¶• íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
    # UploadedFile ê°ì²´ì¸ ê²½ìš° íŒŒì¼ëª… í™•ì¸
    if hasattr(user_csv, 'name'):
        file_name = user_csv.name
    else:
        file_name = str(user_csv)
        
    if file_name.endswith('.zip'):
        with zipfile.ZipFile(user_csv, 'r') as zip_ref:
            # ZIP íŒŒì¼ ë‚´ì˜ CSV íŒŒì¼ëª… ì°¾ê¸°
            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
            if csv_files:
                with zip_ref.open(csv_files[0]) as f:
                    df = pd.read_csv(f, dtype={"user_device_id": str})
            else:
                raise FileNotFoundError(f"No CSV file found in {user_csv}")
    else:
        df = pd.read_csv(user_csv, dtype={"user_device_id": str})
    if "user_device_id" not in df.columns:
        raise ValueError("ì‚¬ìš©ì CSVì— 'user_device_id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì‚¬ìš©ì ë°ì´í„°ì—ì„œ pref_ ì ‘ë‘ì‚¬ê°€ ë¶™ì€ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•„ì„œ ë§¤í•‘
    user_feat_cols = []
    for feat in feat_cols_hint:
        pref_feat = f"pref_{feat}"
        if pref_feat in df.columns:
            user_feat_cols.append(pref_feat)
    
    if not user_feat_cols:
        raise ValueError(f"ì‚¬ìš©ì ë°ì´í„°ì— pref_ ì ‘ë‘ì‚¬ê°€ ë¶™ì€ í”¼ì²˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ê´‘ê³  í”¼ì²˜: {feat_cols_hint[:5]}...")
    
    # ì‚¬ìš©ì ë°ì´í„°ì—ì„œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    use = df[["user_device_id"] + user_feat_cols].copy()
    use[user_feat_cols] = use[user_feat_cols].astype(np.float32).fillna(0.0)
    
    # NumPy ë°°ì—´ë¡œ ë³€í™˜
    U = use[user_feat_cols].to_numpy()
    
    # ì°¨ì›ì´ ë§ì§€ ì•Šìœ¼ë©´ ê´‘ê³  í”¼ì²˜ ìˆ˜ì— ë§ì¶°ì„œ ì¡°ì •
    if U.shape[1] > len(feat_cols_hint):
        # ë„ˆë¬´ ë§ìœ¼ë©´ ìë¥´ê¸°
        U = U[:, :len(feat_cols_hint)]
    elif U.shape[1] < len(feat_cols_hint):
        # ë¶€ì¡±í•˜ë©´ 0ìœ¼ë¡œ íŒ¨ë”©
        padding = np.zeros((U.shape[0], len(feat_cols_hint) - U.shape[1]), dtype=np.float32)
        U = np.concatenate([U, padding], axis=1)
    
    U = l2_normalize(U)
    ids = use["user_device_id"].astype(str).to_numpy()
    # ì¸ë±ìŠ¤ ë§µ(ë¹ ë¥¸ ì¡°íšŒ)
    id_to_row = {uid: i for i, uid in enumerate(ids)}
    
    # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ (total_interactions, unique_ads ë“±)
    interaction_info = {}
    if "total_interactions" in df.columns and "unique_ads" in df.columns:
        for _, row in df.iterrows():
            uid = str(row["user_device_id"])
            interaction_info[uid] = {
                "total_interactions": int(row.get("total_interactions", 0)),
                "unique_ads": int(row.get("unique_ads", 0)),
                "total_reward_points": float(row.get("total_reward_points", 0)),
                "avg_dwell_time": float(row.get("avg_dwell_time", 0))
            }
    
    return U, ids, id_to_row, user_feat_cols, interaction_info

# parse_exclude_codes í•¨ìˆ˜ ì œê±° (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

def recommend_for_user(
    uid: str,
    U: np.ndarray,
    user_ids: np.ndarray,
    id_to_row: Dict[str, int],
    A: np.ndarray,
    ads_meta: pd.DataFrame,
    k: int = 20,
    exclude_codes: Set[str] = None
) -> pd.DataFrame:
    if uid not in id_to_row:
        raise KeyError(f"ì‚¬ìš©ì '{uid}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    u = U[id_to_row[uid] : id_to_row[uid] + 1]     # shape (1, d)
    
    # ì°¨ì› í™•ì¸ ë° ë””ë²„ê¹…
    st.write(f"ğŸ” ë””ë²„ê¹…: ì‚¬ìš©ì ë²¡í„° ì°¨ì›: {u.shape}, ê´‘ê³  ë²¡í„° ì°¨ì›: {A.shape}")
    st.write(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ìˆ˜: {u.shape[1]}ê°œ")
    
    # ì°¨ì›ì´ ë§ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€
    if u.shape[1] != A.shape[1]:
        st.error(f"âŒ ì°¨ì› ë¶ˆì¼ì¹˜: ì‚¬ìš©ì {u.shape[1]}ì°¨ì› vs ê´‘ê³  {A.shape[1]}ì°¨ì›")
        st.stop()
    
    # ì½”ì‚¬ì¸ ì ìˆ˜ (A, Uê°€ l2-normalized)
    scores = (u @ A.T).reshape(-1).astype(np.float32)  # (N_ads,)
    
    # ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ê°€ì ¸ì˜¤ê¸°
    user_interacted_types = set()
    user_interacted_categories = set()
    
    # actual_interactionsì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    if uid in actual_interactions and actual_interactions[uid]:
        for interaction in actual_interactions[uid]:
            user_interacted_types.add(interaction.get('ads_type'))
            user_interacted_categories.add(interaction.get('ads_category'))
    
    # íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë³´ë„ˆìŠ¤ ì ìš© (ê³ ì •ê°’)
    type_category_bonus = 0.05  # ê³ ì • ë³´ë„ˆìŠ¤ ê°’ (50% ê°ì†Œ)
    
    # ì•ˆì „í•œ ì¸ë±ìŠ¤ ì ‘ê·¼ì„ ìœ„í•´ ads_meta ê¸¸ì´ í™•ì¸
    if len(ads_meta) != len(scores):
        st.error(f"âŒ ë°ì´í„° ë¶ˆì¼ì¹˜: ê´‘ê³  ë©”íƒ€ë°ì´í„° {len(ads_meta)}ê°œ vs ì ìˆ˜ ë°°ì—´ {len(scores)}ê°œ")
        st.stop()
    
    # ads_metaì˜ ì¸ë±ìŠ¤ë¥¼ scores ë°°ì—´ ì¸ë±ìŠ¤ì™€ ë§¤ì¹­
    for i, (_, ad_row) in enumerate(ads_meta.iterrows()):
        # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬
        if i >= len(scores):
            break
            
        ad_type = ad_row['ads_type']
        ad_category = ad_row['ads_category']
        
        # íƒ€ì…ê³¼ ì¹´í…Œê³ ë¦¬ê°€ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        if ad_type in user_interacted_types and ad_category in user_interacted_categories:
            scores[i] += type_category_bonus
        # íƒ€ì…ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        elif ad_type in user_interacted_types:
            scores[i] += type_category_bonus * 0.5
        # ì¹´í…Œê³ ë¦¬ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        elif ad_category in user_interacted_categories:
            scores[i] += type_category_bonus * 0.3
    
    if exclude_codes:
        mask_excl = ads_meta["ads_code"].isin(exclude_codes).to_numpy()
        scores[mask_excl] = -np.inf
    
    take = min(k, scores.shape[0])
    idx = np.argpartition(scores, -take)[-take:]
    idx = idx[np.argsort(-scores[idx])]
    sel = ads_meta.iloc[idx].copy()
    sel.insert(0, "rank", np.arange(1, len(idx) + 1, dtype=np.int32))
    sel["final_score"] = scores[idx].astype(np.float32)
    # ì¶œë ¥ ì—´ ì •ëˆ (ads_name ì¶”ê°€)
    result = sel[["rank","ads_idx","ads_code","ads_name","ads_type","ads_category","final_score"]].copy()
    # ì»¬ëŸ¼ëª…ì„ í•œêµ­ì–´ë¡œ ë³€ê²½
    result.columns = ["ìˆœìœ„", "ê´‘ê³ ì¸ë±ìŠ¤", "ê´‘ê³ ì½”ë“œ", "ê´‘ê³ ëª…", "ê´‘ê³ íƒ€ì…", "ê´‘ê³ ì¹´í…Œê³ ë¦¬", "ìµœì¢…ì ìˆ˜"]
    return result

# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="ì¶”ì²œ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ¯ ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ")

with st.sidebar:
    st.header("ì„¤ì •")
    k = st.slider("ì¶”ì²œ ê°œìˆ˜ (Top-K)", min_value=1, max_value=50, value=20, step=1)
    
    st.markdown("---")
    st.caption("ğŸ’¡ ëŒ€ìš©ëŸ‰ CSVëŠ” ìµœì´ˆ ë¡œë”©ì— ì‹œê°„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
st.subheader("ğŸ“ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)")

# íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ë“¤
col1, col2, col3 = st.columns(3)

with col1:
    ads_file = st.file_uploader(
        "ê´‘ê³  í”„ë¡œí•„ íŒŒì¼",
        type=['csv', 'zip'],
        help="ads_profile.csv ë˜ëŠ” ads_profile.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        key="ads_upload"
    )

with col2:
    users_file = st.file_uploader(
        "ì‚¬ìš©ì í”„ë¡œí•„ íŒŒì¼",
        type=['csv', 'zip'],
        help="user_profile.csv ë˜ëŠ” user_profile.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        key="users_upload"
    )

with col3:
    interactions_file = st.file_uploader(
        "ìƒí˜¸ì‘ìš© ë°ì´í„° íŒŒì¼",
        type=['csv', 'zip'],
        help="correct_interactions.csv ë˜ëŠ” correct_interactions.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        key="interactions_upload"
    )

# íŒŒì¼ ì—…ë¡œë“œê°€ ë³€ê²½ë˜ë©´ ì„±ê³µ ë©”ì‹œì§€ ìƒíƒœ ë¦¬ì…‹
if any([ads_file, users_file, interactions_file]):
    if "data_loaded_successfully" in st.session_state:
        del st.session_state["data_loaded_successfully"]

# ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìƒ˜í”Œ ë°ì´í„° ìš°ì„  ì‚¬ìš©)
if ads_file is None:
    # ìƒ˜í”Œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ ë°ì´í„° ì‚¬ìš©
    if os.path.exists("ads_profile_sample.zip"):
        ads_file_path = "ads_profile_sample.zip"
    elif os.path.exists("ads_profile.zip"):
        ads_file_path = "ads_profile.zip"
    else:
        st.error("âŒ ê´‘ê³  ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()
else:
    ads_file_path = ads_file

if users_file is None:
    if os.path.exists("user_profile_sample.zip"):
        users_file_path = "user_profile_sample.zip"
    elif os.path.exists("user_profile.zip"):
        users_file_path = "user_profile.zip"
    else:
        st.error("âŒ ì‚¬ìš©ì ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()
else:
    users_file_path = users_file

if interactions_file is None:
    if os.path.exists("correct_interactions_sample.zip"):
        interactions_file_path = "correct_interactions_sample.zip"
    elif os.path.exists("correct_interactions.zip"):
        interactions_file_path = "correct_interactions.zip"
    else:
        st.error("âŒ ìƒí˜¸ì‘ìš© ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()
else:
    interactions_file_path = interactions_file

st.divider()

# ë°ì´í„° ë¡œë“œ
try:
    # íŒŒì¼ ê²½ë¡œ ë””ë²„ê¹… ì •ë³´ (10ì´ˆ í›„ ìë™ ì‚¬ë¼ì§)
    debug_placeholder = st.empty()
    with debug_placeholder.container():
        st.write(f"ğŸ” ë””ë²„ê¹…: ê´‘ê³  íŒŒì¼ ê²½ë¡œ: {ads_file_path}")
        st.write(f"ğŸ” ë””ë²„ê¹…: ì‚¬ìš©ì íŒŒì¼ ê²½ë¡œ: {users_file_path}")
        st.write(f"ğŸ” ë””ë²„ê¹…: ìƒí˜¸ì‘ìš© íŒŒì¼ ê²½ë¡œ: {interactions_file_path}")
    
    # 10ì´ˆ í›„ ë””ë²„ê¹… ì •ë³´ ì œê±°
    import time
    time.sleep(10)
    debug_placeholder.empty()
    
    with st.spinner("ê´‘ê³  ë°ì´í„° ë¡œë”© ì¤‘..."):
        A, feat_cols_ads, ads_meta = load_ads(ads_file_path)
    with st.spinner("ì‚¬ìš©ì ë°ì´í„° ë¡œë”© ì¤‘..."):
        U, user_ids, id_to_row, feat_cols_user, interaction_info = load_users(users_file_path, feat_cols_ads)
    with st.spinner("ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë”© ì¤‘..."):
        user_interactions = load_interactions_from_user_profile(users_file_path)
        actual_interactions = load_actual_interactions(interactions_file_path)
        detailed_interactions = load_detailed_user_interactions(users_file_path)
    
    # ë°ì´í„° ë¡œë”© ì„±ê³µ ë©”ì‹œì§€ (ì²˜ìŒ ë¡œë”©í•  ë•Œë§Œ í‘œì‹œ)
    if "data_loaded_successfully" not in st.session_state:
        success_placeholder = st.empty()
        success_placeholder.success("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # 10ì´ˆ í›„ ë©”ì‹œì§€ ì œê±°
        import time
        time.sleep(10)
        success_placeholder.empty()
        
        # ì„¸ì…˜ ìƒíƒœì— ì„±ê³µ í‘œì‹œ ì €ì¥
        st.session_state["data_loaded_successfully"] = True
    
except Exception as e:
    st.error(f"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
    st.error("ğŸ’¡ í•´ê²° ë°©ë²•:")
    st.error("1. íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸í•˜ì„¸ìš” (CSV ë˜ëŠ” ZIP)")
    st.error("2. íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í¬ì§€ ì•Šì€ì§€ í™•ì¸í•˜ì„¸ìš”")
    st.error("3. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ë³´ì„¸ìš”")
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
    import traceback
    st.error("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
    st.code(traceback.format_exc())
    
    st.stop()

# ì‚¬ìš©ì ì„ íƒ
st.subheader("1ï¸âƒ£ ì‚¬ìš©ì ì„ íƒ")
col1, col2 = st.columns([4,1])

with col1:
    st.markdown("**ì‚¬ìš©ì ID ì„ íƒ**")
    if len(user_ids) > 0:
        # ëœë¤ ì„ íƒëœ ì‚¬ìš©ìê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        if "random_uid" in st.session_state:
            random_uid = st.session_state["random_uid"]
            try:
                selected_index = list(user_ids).index(random_uid) + 1  # +1 because of empty option
            except ValueError:
                selected_index = 0
        else:
            selected_index = 0
            
        uid_input = st.selectbox(
            "ì‚¬ìš©ì ì„ íƒ", 
            options=[""] + list(user_ids),
            index=selected_index,
            help="ë“œë¡­ë‹¤ìš´ì—ì„œ ì‚¬ìš©ìë¥¼ ì„ íƒí•˜ì„¸ìš”",
            label_visibility="collapsed"
        )
    else:
        st.warning("ì‚¬ìš©ì ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        uid_input = ""

with col2:
    st.markdown("**ëœë¤ ì„ íƒ**")
    if st.button("ğŸ²", use_container_width=True, help="ë¬´ì‘ìœ„ ì‚¬ìš©ì ì„ íƒ"):
        # ë¬´ì‘ìœ„ í•œ ëª…
        if len(user_ids) > 0:
            random_uid = np.random.choice(user_ids)
            st.session_state["random_uid"] = random_uid
            st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ selectbox ì—…ë°ì´íŠ¸
        else:
            st.warning("ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì¶”ì²œ ì‹¤í–‰
st.subheader("2ï¸âƒ£ ì¶”ì²œ ì‹¤í–‰")
run = st.button("ğŸš€ ì¶”ì²œ ì‹œì‘", type="primary", use_container_width=True)

if run:
    if not uid_input:
        st.warning("ì‚¬ìš©ì IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()
    try:
        with st.spinner("ì½˜í…ì¸  ê¸°ë°˜ Top-K ì¶”ì²œ ê³„ì‚° ì¤‘..."):
            rec = recommend_for_user(
                uid=uid_input,
                U=U,
                user_ids=user_ids,
                id_to_row=id_to_row,
                A=A,
                ads_meta=ads_meta,
                k=k,
                exclude_codes=None
            )
        st.success(f"âœ… ì‚¬ìš©ì {uid_input}ì— ëŒ€í•œ Top-{k} ì¶”ì²œ ê²°ê³¼")
        
        # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ í‘œì‹œ
        if uid_input in interaction_info:
            user_info = interaction_info[uid_input]
            st.markdown("**ğŸ‘¤ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´**")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ìƒí˜¸ì‘ìš© ìˆ˜ ê³„ì‚°
                if uid_input in actual_interactions and actual_interactions[uid_input]:
                    actual_total_interactions = len(actual_interactions[uid_input])
                    st.metric("ì´ ìƒí˜¸ì‘ìš©", actual_total_interactions)
                else:
                    st.metric("ì´ ìƒí˜¸ì‘ìš©", user_info["total_interactions"])
            with col2:
                # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ê³ ìœ  ê´‘ê³  ìˆ˜ ê³„ì‚°
                if uid_input in actual_interactions and actual_interactions[uid_input]:
                    unique_ads_count = len(set(interaction['ads_idx'] for interaction in actual_interactions[uid_input]))
                    st.metric("ê³ ìœ  ê´‘ê³  ìˆ˜", unique_ads_count)
                else:
                    st.metric("ê³ ìœ  ê´‘ê³  ìˆ˜", user_info["unique_ads"])
            with col3:
                # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ í´ë¦­+ì „í™˜ì¸ ìƒí˜¸ì‘ìš©ë“¤ì˜ ë¦¬ì›Œë“œ í•© ê³„ì‚°
                if uid_input in actual_interactions and actual_interactions[uid_input]:
                    total_rwd_price = sum(
                        interaction.get('rwd_price', 0) 
                        for interaction in actual_interactions[uid_input] 
                        if interaction.get('interaction_type') == 'í´ë¦­+ì „í™˜'  # í´ë¦­+ì „í™˜ì¸ ìƒí˜¸ì‘ìš©ë§Œ
                    )
                    st.metric("ì´ ë¦¬ì›Œë“œ ê¸ˆì•¡", f"{total_rwd_price:.0f}ì› ({total_rwd_price:.0f}í¬ì¸íŠ¸)")
                else:
                    st.metric("ì´ ë¦¬ì›Œë“œ ê¸ˆì•¡", f"{user_info['total_reward_points']:.0f}ì› ({user_info['total_reward_points']:.0f}í¬ì¸íŠ¸)")
        
        # ì‚¬ìš©ìê°€ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡ í‘œì‹œ
        st.markdown("**ğŸ“‹ ì‚¬ìš©ìê°€ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡**")
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ì‚¬ìš©
        if uid_input in actual_interactions and actual_interactions[uid_input]:
            # ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë“¤ í‘œì‹œ (ì¤‘ë³µ ì§‘ê³„)
            actual_ads = {}
            for interaction in actual_interactions[uid_input]:
                ads_idx = interaction['ads_idx']
                # ads_idxë¡œ ê´‘ê³  ì •ë³´ ì°¾ê¸° (ì•ˆì „í•œ ì ‘ê·¼)
                ad_info = ads_meta[ads_meta['ads_idx'] == ads_idx]
                if len(ad_info) > 0:
                    ad_row = ad_info.iloc[0]
                    # ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œëŠ” interaction_typeì´ ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ë¨
                    clean_interaction_type = str(interaction['interaction_type'])
                    
                    # ê´‘ê³ ë³„ë¡œ ìƒí˜¸ì‘ìš© ì§‘ê³„
                    ad_key = f"{ad_row['ads_code']}_{clean_interaction_type}"
                    if ad_key not in actual_ads:
                        actual_ads[ad_key] = {
                            "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                            "ê´‘ê³ ëª…": ad_row["ads_name"],
                            "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                            "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                            "ìƒí˜¸ì‘ìš©ìœ í˜•": clean_interaction_type,
                            "ìƒí˜¸ì‘ìš©íšŸìˆ˜": 0
                        }
                    actual_ads[ad_key]["ìƒí˜¸ì‘ìš©íšŸìˆ˜"] += 1
            
            # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            actual_ads_list = list(actual_ads.values())
            
            if actual_ads_list:
                actual_df = pd.DataFrame(actual_ads_list)
                st.dataframe(actual_df, use_container_width=True, hide_index=True)
                st.info(f"ğŸ’¡ ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡ì…ë‹ˆë‹¤. (ì´ {len(actual_ads_list)}ê°œ)")
            else:
                st.info("ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒì„¸ ìƒí˜¸ì‘ìš© ë°ì´í„° ì‚¬ìš©
        elif uid_input in detailed_interactions and detailed_interactions[uid_input]:
            # ìƒì„¸ ìƒí˜¸ì‘ìš© ì •ë³´ë¡œ ì‹¤ì œ ê´‘ê³ ë“¤ ìƒì„±
            detailed_ads = []
            max_interactions = user_info.get("total_interactions", 0)
            
            for interaction in detailed_interactions[uid_input]:
                # ì´ ìƒí˜¸ì‘ìš© ìˆ˜ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œ
                if len(detailed_ads) >= max_interactions:
                    break
                    
                if interaction['category'] is not None:
                    # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê´‘ê³  ì°¾ê¸°
                    category_ads = ads_meta[ads_meta["ads_category"] == interaction['category']]
                    if len(category_ads) > 0:
                        # ëœë¤í•˜ê²Œ ì„ íƒ (ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜)
                        ad_row = category_ads.sample(1).iloc[0]
                        detailed_ads.append({
                            "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                            "ê´‘ê³ ëª…": ad_row["ads_name"],
                            "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                            "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                            "ìƒí˜¸ì‘ìš©ìœ í˜•": interaction['interaction_type'],
                            "ìƒí˜¸ì‘ìš©íšŸìˆ˜": interaction['count']
                        })
                
                if interaction['type'] is not None and len(detailed_ads) < max_interactions:
                    # íƒ€ì… ê¸°ë°˜ ê´‘ê³  ì°¾ê¸°
                    type_ads = ads_meta[ads_meta["ads_type"] == interaction['type']]
                    if len(type_ads) > 0:
                        # ëœë¤í•˜ê²Œ ì„ íƒ (ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜)
                        ad_row = type_ads.sample(1).iloc[0]
                        # ì¤‘ë³µ ë°©ì§€
                        if not any(ad["ê´‘ê³ ì½”ë“œ"] == ad_row["ads_code"] for ad in detailed_ads):
                            detailed_ads.append({
                                "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                                "ê´‘ê³ ëª…": ad_row["ads_name"],
                                "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                                "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                                "ìƒí˜¸ì‘ìš©ìœ í˜•": interaction['interaction_type'],
                                "ìƒí˜¸ì‘ìš©íšŸìˆ˜": interaction['count']
                            })
            
            if detailed_ads:
                detailed_df = pd.DataFrame(detailed_ads)
                st.dataframe(detailed_df, use_container_width=True, hide_index=True)
                st.info(f"ğŸ’¡ ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³  ëª©ë¡ì…ë‹ˆë‹¤. (ì´ {len(detailed_ads)}ê°œ)")
            else:
                st.info("ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ëŒ€í‘œ ê´‘ê³  ì‚¬ìš©
        elif uid_input in user_interactions and user_interactions[uid_input]:
            # ëŒ€í‘œ ê´‘ê³  í‘œì‹œ (ê¸°ì¡´ ë¡œì§)
            interaction_data = user_interactions[uid_input]
            categories = interaction_data.get("categories", [])
            types = interaction_data.get("types", [])
            
            # ì‹¤ì œ ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë§Œ í‘œì‹œ (ì´ ìƒí˜¸ì‘ìš© ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡)
            interacted_ads = []
            
            # ì‹¤ì œ ìƒí˜¸ì‘ìš© íŒ¨í„´ì— ë”°ë¼ ê´‘ê³  í‘œì‹œ
            for category in categories:
                if len(interacted_ads) >= user_info.get("total_interactions", 0):
                    break
                
                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê´‘ê³  ì¤‘ì—ì„œ ìƒí˜¸ì‘ìš©í•œ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì°¾ê¸°
                category_ads = ads_meta[ads_meta["ads_category"] == category]
                
                # ìƒí˜¸ì‘ìš©í•œ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ” ê´‘ê³ ê°€ ìˆëŠ”ì§€ í™•ì¸
                matching_ads = category_ads[category_ads["ads_type"].isin(types)]
                
                if len(matching_ads) > 0:
                    # êµì§‘í•©ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê´‘ê³  ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ì™€ íƒ€ì… ëª¨ë‘ ìƒí˜¸ì‘ìš©)
                    ad_row = matching_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "í´ë¦­+ì „í™˜"
                    })
                else:
                    # êµì§‘í•©ì´ ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ë§Œ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ë§Œ ìƒí˜¸ì‘ìš©)
                    ad_row = category_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "í´ë¦­"
                    })
            
            # íƒ€ì… ê¸°ë°˜ ê´‘ê³  ì°¾ê¸° (ì¹´í…Œê³ ë¦¬ì™€ êµì§‘í•©ì´ ì—†ëŠ” ê²½ìš°ë§Œ)
            for ad_type in types:
                if len(interacted_ads) >= user_info.get("total_interactions", 0):
                    break
                
                # ì´ë¯¸ í•´ë‹¹ íƒ€ì…ì´ í¬í•¨ëœ ê´‘ê³ ê°€ ìˆëŠ”ì§€ í™•ì¸
                if any(ad["ê´‘ê³ íƒ€ì…"] == ad_type for ad in interacted_ads):
                    continue
                
                # í•´ë‹¹ íƒ€ì…ì˜ ê´‘ê³  ì¤‘ì—ì„œ ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì°¾ê¸°
                type_ads = ads_meta[ads_meta["ads_type"] == ad_type]
                matching_ads = type_ads[type_ads["ads_category"].isin(categories)]
                
                if len(matching_ads) > 0:
                    # êµì§‘í•©ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê´‘ê³  ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ì™€ íƒ€ì… ëª¨ë‘ ìƒí˜¸ì‘ìš©)
                    ad_row = matching_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "í´ë¦­+ì „í™˜"
                    })
                else:
                    # êµì§‘í•©ì´ ì—†ìœ¼ë©´ íƒ€ì…ë§Œ ì¼ì¹˜í•˜ëŠ” ê´‘ê³  ì‚¬ìš© (íƒ€ì…ë§Œ ìƒí˜¸ì‘ìš©)
                    ad_row = type_ads.iloc[0]
                    interacted_ads.append({
                        "ê´‘ê³ ì½”ë“œ": ad_row["ads_code"],
                        "ê´‘ê³ ëª…": ad_row["ads_name"],
                        "ê´‘ê³ íƒ€ì…": ad_row["ads_type"],
                        "ê´‘ê³ ì¹´í…Œê³ ë¦¬": ad_row["ads_category"],
                        "ìƒí˜¸ì‘ìš©ìœ í˜•": "ì „í™˜"
                    })
            
            if interacted_ads:
                interacted_df = pd.DataFrame(interacted_ads)
                st.dataframe(interacted_df, use_container_width=True, hide_index=True)
                
                # ìš”ì•½ ì •ë³´
                st.info(f"ğŸ’¡ ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬/íƒ€ì…ì˜ ëŒ€í‘œ ê´‘ê³ ì…ë‹ˆë‹¤. (ì´ {len(interacted_ads)}ê°œ)")
            else:
                st.info("ìƒí˜¸ì‘ìš©í•œ ê´‘ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì´ ì‚¬ìš©ìëŠ” ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ì‚¬ìš©ì ì„ í˜¸ë„ vs ì¶”ì²œ ê²°ê³¼ ë¹„êµ
        st.markdown("**ğŸ¯ ì‚¬ìš©ì ì„ í˜¸ë„ vs ì¶”ì²œ ê²°ê³¼ ë¹„êµ**")
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        user_vector = U[id_to_row[uid_input]]
        
        # ì¶”ì²œëœ ê´‘ê³ ë“¤ì˜ í”¼ì²˜ ë²¡í„°
        rec_ads_idx = rec["ê´‘ê³ ì¸ë±ìŠ¤"].values
        
        # ads_idxë¥¼ A ë°°ì—´ì˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        rec_ads_indices = []
        for ads_idx in rec_ads_idx:
            # ads_metaì—ì„œ í•´ë‹¹ ads_idxì˜ í–‰ ì¸ë±ìŠ¤ ì°¾ê¸°
            ad_row_idx = ads_meta[ads_meta['ads_idx'] == ads_idx].index
            if len(ad_row_idx) > 0:
                rec_ads_indices.append(ad_row_idx[0])
            else:
                st.warning(f"ê´‘ê³  ì¸ë±ìŠ¤ {ads_idx}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
        
        if rec_ads_indices:
            rec_ads_features = A[rec_ads_indices]
        else:
            st.error("ì¶”ì²œëœ ê´‘ê³ ì˜ í”¼ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ì™€ ê° ì¶”ì²œ ê´‘ê³ ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = (user_vector @ rec_ads_features.T).flatten()
        
        # ë¹„êµ ì°¨íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“ˆ ì¶”ì²œ ê´‘ê³ ë³„ ìœ ì‚¬ë„**")
            # ìœ ì‚¬ë„ë¥¼ ì„¸ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ë¡œ í‘œì‹œ
            sim_data = pd.DataFrame({
                "ìœ ì‚¬ë„": similarities
            }, index=rec["ìˆœìœ„"])
            st.bar_chart(sim_data, use_container_width=True)
        
        with col2:
            st.markdown("**ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„í¬**")
            # ì¹´í…Œê³ ë¦¬ ë¶„í¬ë¥¼ ì„¸ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ë¡œ í‘œì‹œ
            cat_data = pd.DataFrame({
                "ê°œìˆ˜": rec["ê´‘ê³ ì¹´í…Œê³ ë¦¬"].value_counts().sort_index()
            })
            st.bar_chart(cat_data, use_container_width=True)
        
        # ìœ ì‚¬ë„ í†µê³„
        st.markdown("**ğŸ“‹ ìœ ì‚¬ë„ ë¶„ì„**")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("í‰ê·  ìœ ì‚¬ë„", f"{similarities.mean():.4f}")
        with col2:
            st.metric("ìµœê³  ìœ ì‚¬ë„", f"{similarities.max():.4f}")
        with col3:
            st.metric("ìµœì € ìœ ì‚¬ë„", f"{similarities.min():.4f}")
        with col4:
            st.metric("ìœ ì‚¬ë„ í‘œì¤€í¸ì°¨", f"{similarities.std():.4f}")
        
        # ìƒì„¸ ë¶„ì„ í…Œì´ë¸”
        st.markdown("**ğŸ” ì¶”ì²œ ê´‘ê³  ìƒì„¸ ë¶„ì„**")
        
        # ìµœì¢…ì ìˆ˜ ê³„ì‚° ë°©ì‹ ì„¤ëª…
        with st.expander("ğŸ“Š ìµœì¢…ì ìˆ˜ ê³„ì‚° ë°©ì‹"):
            st.markdown(f"""
            **ìµœì¢…ì ìˆ˜ = ì½˜í…ì¸  ìœ ì‚¬ë„ + íƒ€ì…/ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë³´ë„ˆìŠ¤**
            
            **1. ì½˜í…ì¸  ìœ ì‚¬ë„ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)**
            - **ì‚¬ìš©ì ë²¡í„° (U)**: ì‚¬ìš©ìì˜ ì„ í˜¸ë„ í”¼ì²˜ ë²¡í„° (60ì°¨ì›)
            - **ê´‘ê³  ë²¡í„° (A)**: ê´‘ê³ ì˜ ì½˜í…ì¸  í”¼ì²˜ ë²¡í„° (60ì°¨ì›)
            - **ê³„ì‚° ë°©ì‹**: `scores = user_vector @ ads_features.T`
            - **ì •ê·œí™”**: L2 ì •ê·œí™”ëœ ë²¡í„°ë“¤ì˜ ë‚´ì  (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            - **ë²”ìœ„**: -1 ~ 1 (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨)
            
            **2. íƒ€ì…/ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë³´ë„ˆìŠ¤ (ê³ ì •ê°’: 0.05)**
            - **íƒ€ì…+ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì¼ì¹˜**: +0.05 (100% ë³´ë„ˆìŠ¤)
            - **íƒ€ì…ë§Œ ì¼ì¹˜**: +0.025 (50% ë³´ë„ˆìŠ¤)
            - **ì¹´í…Œê³ ë¦¬ë§Œ ì¼ì¹˜**: +0.015 (30% ë³´ë„ˆìŠ¤)
            
            **ì¶”ê°€ ë¶„ì„ ìš”ì†Œë“¤:**
            - **ìœ ì‚¬ë„**: ì½˜í…ì¸  ìœ ì‚¬ë„ (ë³´ë„ˆìŠ¤ ì ìš© ì „)
            - **íƒ€ì…ì„ í˜¸ë„**: ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë°˜ íƒ€ì… ì„ í˜¸ë„
            - **ì¹´í…Œê³ ë¦¬ì„ í˜¸ë„**: ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
            - **ìƒëŒ€ìˆœìœ„(%)**: ì „ì²´ ì¶”ì²œ ì¤‘ì—ì„œì˜ ë°±ë¶„ìœ„ ìˆœìœ„
            """)
        detailed_df = rec.copy()
        detailed_df["ìœ ì‚¬ë„"] = similarities
        
        # ì¶”ê°€ ë¶„ì„ ì •ë³´ ê³„ì‚°
        user_vector = U[id_to_row[uid_input]]
        
        # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ê³„ì‚° (ì‚¬ìš©ì ë²¡í„°ì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê´€ë ¨ í”¼ì²˜ë“¤ì˜ í‰ê· )
        category_preferences = []
        type_preferences = []
        
        for _, row in detailed_df.iterrows():
            # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ (ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ ê¸°ë°˜)
            category = row["ê´‘ê³ ì¹´í…Œê³ ë¦¬"]
            if uid_input in user_interactions:
                interacted_cats = user_interactions[uid_input].get("categories", [])
                if category in interacted_cats:
                    cat_pref = 0.8  # ìƒí˜¸ì‘ìš©í•œ ì¹´í…Œê³ ë¦¬ëŠ” ë†’ì€ ì„ í˜¸ë„
                else:
                    cat_pref = 0.4  # ìƒí˜¸ì‘ìš©í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ëŠ” ë‚®ì€ ì„ í˜¸ë„
            else:
                cat_pref = 0.5  # ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¤‘ê°„ ì„ í˜¸ë„
            category_preferences.append(cat_pref)
            
            # íƒ€ì… ì„ í˜¸ë„ (ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì •ë³´ ê¸°ë°˜)
            ad_type = row["ê´‘ê³ íƒ€ì…"]
            if uid_input in user_interactions:
                interacted_types = user_interactions[uid_input].get("types", [])
                if ad_type in interacted_types:
                    type_pref = 0.7  # ìƒí˜¸ì‘ìš©í•œ íƒ€ì…ì€ ë†’ì€ ì„ í˜¸ë„
                else:
                    type_pref = 0.3  # ìƒí˜¸ì‘ìš©í•˜ì§€ ì•Šì€ íƒ€ì…ì€ ë‚®ì€ ì„ í˜¸ë„
            else:
                type_pref = 0.5  # ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¤‘ê°„ ì„ í˜¸ë„
            type_preferences.append(type_pref)
        
        detailed_df["ì¹´í…Œê³ ë¦¬ì„ í˜¸ë„"] = category_preferences
        detailed_df["íƒ€ì…ì„ í˜¸ë„"] = type_preferences
        
        # ìƒëŒ€ì  ìˆœìœ„ (ì „ì²´ ê´‘ê³  ì¤‘ì—ì„œì˜ ë°±ë¶„ìœ„)
        total_ads = len(ads_meta)
        relative_ranks = []
        for rank in detailed_df["ìˆœìœ„"]:
            percentile = (1 - (rank - 1) / len(detailed_df)) * 100
            relative_ranks.append(percentile)
        detailed_df["ìƒëŒ€ìˆœìœ„(%)"] = relative_ranks
        
        # ìµœì¢… í…Œì´ë¸” êµ¬ì„±
        detailed_df = detailed_df[["ìˆœìœ„", "ê´‘ê³ ì½”ë“œ", "ê´‘ê³ ëª…", "ê´‘ê³ íƒ€ì…", "ê´‘ê³ ì¹´í…Œê³ ë¦¬", 
                                 "ìµœì¢…ì ìˆ˜", "ìœ ì‚¬ë„", "íƒ€ì…ì„ í˜¸ë„", "ì¹´í…Œê³ ë¦¬ì„ í˜¸ë„", "ìƒëŒ€ìˆœìœ„(%)"]]
        
        st.dataframe(detailed_df, use_container_width=True, hide_index=True)

        # ë‹¤ìš´ë¡œë“œ
        csv_bytes = rec.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_bytes,
            file_name=f"top{k}_{uid_input}_recommendations.csv",
            mime="text/csv",
            use_container_width=True
        )

    except KeyError as e:
        st.error(f"ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        st.error(f"ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì•± ì‹œì‘ ì‹œ ì••ì¶• íŒŒì¼ í•´ì œ
if __name__ == "__main__":
    # ì••ì¶• í•´ì œ ê¸°ëŠ¥ ì œê±°ë¨ - ì••ì¶• íŒŒì¼ì„ ì§ì ‘ ì‚¬ìš©
    pass
